import os
import re
import subprocess
import itertools

samples_file = config['samples_file']
samples_dict = {}

with open(samples_file) as f:
    first_line = True

    for line in f:
        if first_line: # Skip header line
            continue
        
        columns = line.strip().split("\t")

        if len(columns) != 4:
            raise ValueError("Invalid sample list format. Sample list should be of format: group_name\tsample_name\tfastq_filename1\tfastq_filename2")
        
        group = columns[0]
        sample = columns[1]
        filename1 = columns[2]
        filename2 = columns[3]

        # Check if sample name already exists in the dictionary, if not, add it
        if sample not in samples_dict:
            samples_dict[sample] = {'group': group, 'filename1': filename1, 'filename2': filename2}

            with open ( 'samples.list', "w" ) as file: # Write sample.list file
                print ( f"{sample}\t{group}", file=file )
        else:
            pass


# Extract unique group and sample names
group_names = list(set(sample_info['group'] for sample_info in samples_dict.values()))
samples = list(sample_info for sample_info in samples_dict.keys())

## create comparisons based on sample names ##
def all_pairs (groups):
    comparisons = {}
    
    for group1, group2 in itertools.combinations(groups, 2):
        comparisons[str(group1+"_"+group2)]=str(group1+"_vs_"+group2)   
    return list(comparisons.values())                   

de_subset = all_pairs(group_names)


## ====================================================== ANALYSIS ====================================================== ##

rule all:
    input:
        expand("edgeR/02_analyze_DE/{de_subset}.P1e-3_C{log2FC_cutoff}.DE.xlsx",
               de_subset=de_subset,
               log2FC_cutoff=config['log2FC_cutoff'])

rule index:
    input: fasta = config['fasta']
    output: directory("{group_names}.salmon.index")
    conda: "envs/salmon.yaml"
    shell: """ salmon index -t {input.fasta} -i {output} --keepDuplicates """

    
rule selective_alignment:
    input: fastq1 = "{samples}_1.trimmed.fastq.gz",
           fastq2 ="{samples}_2.trimmed.fastq.gz"
    output: directory("{samples}.salmon.quants")
    conda: "envs/salmon.yaml"
    threads: config['mapping_threads']
    shell: """ salmon quant -i {group_names}.salmon.index \
    	       	      	    -l A -1 {input.fastq1} -2 {input.fastq2} \
			    --threads {threads} \
			    --validateMappings \
			    -o {output} """
    
rule quantmerge:
    input: expand("{sample}/quant.sf", sample=samples)
    output:
        counts="counts.mod.txt",
        tpm="all.genes.tpm.tsv",
    conda: "envs/salmon.yaml"
    shell: """ salmon quantmerge --quants {input} --column numreads --output {output.counts} && \
               salmon quantmerge --quants {input} --column TPM --output {output.tpm} """

rule PCA:
    input: tpm="all.genes.tpm.tsv",
           samples_list = "samples.list"
    output: pca="PCA.svg"
    conda: "envs/salmon.yaml"
    shell: """ Rscript scripts/pca.R {input.tpm} {input.samples_list} """
    
rule make_directories:
    input:
        counts_file="counts.mod.txt",
        samples_list= "samples.list",
        pca="PCA.svg"
    output: 'chkp'
    shell: """ mkdir edgeR && \
               cd edgeR && \
               mkdir 01_run_DE_analysis && \
               mkdir 02_analyze_DE && \
               cd ../ && \
               cp results/counts.mod.txt edgeR/01_run_DE_analysis/ && \
               cp {input.samples_list} edgeR/01_run_DE_analysis/ && \
               touch chkp """

rule run_DE_analysis:
    input:
        counts_file="counts.mod.txt",
        samples_list="samples.list",
        chkp='chkp'
    output: 'edgeR/chkp01'
    shell: """ cd edgeR/01_run_DE_analysis && \
               perl scripts/run_DE_analysis.pl --matrix ../../../{input.counts_file} --method edgeR --samples_file ../../results/{input.samples_list} && \
               cd ../ && \
               touch chkp01 """

rule analyze_DE:
    input: 'edgeR/chkp01'
    output: 'edgeR/chkp02'
    params: DE_cutoff = config['log2FC_cutoff']
    shell: """ cd edgeR/02_analyze_DE && \
               ln -s ../01_run_DE_analysis/edgeR.*/counts.mod.txt* . && \
               perl scripts/analyze_diff_expr.pl --matrix ../../results/counts.mod.txt --samples ../01_run_DE_analysis/samples.list -P 1e-3 -C {params.DE_cutoff} && \
               cd ../ && \
               touch chkp02 && \
               rm ../chkp ../{input} ../{output} """

rule rename:
    input: 'edgeR/02_analyze_DE/counts.mod.txt.{de_subset}.edgeR.DE_results.P1e-3_{log2FC_cutoff}.DE.subset'
    output: 'edgeR/02_analyze_DE/{de_subset}.P1e-3_C{log2FC_cutoff}.DE.subset'
    shell: " perl scripts/rename.pl {input} "

rule reverse_sort:
     input: 'edgeR/02_analyze_DE/{de_subset}.P1e-3_{log2FC_cutoff}.DE.tsv'
     output: sorted = 'edgeR/02_analyze_DE/{de_subset}.P1e-3_{log2FC_cutoff}.DE.tsv'            
     shell: """ perl scripts/reverse_sort.pl {input} > {output.sorted} """

rule tsv2xlsx:
     input: 'edgeR/02_analyze_DE/{de_subset}.P1e-3_{log2FC_cutoff}.DE.tsv'
     output: 'edgeR/02_analyze_DE/{de_subset}.P1e-3_{log2FC_cutoff}.DE.xlsx'
     shell: """ python3 scripts/tsv2xlsx.py {input} """
